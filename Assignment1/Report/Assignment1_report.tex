\documentclass[twocolumn]{myarticle}

\usepackage{mymacros}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{booktabs}

\lstset{%
basicstyle=\small\ttfamily,
columns=flexible,
breaklines=true,
numbers=left,
stepnumber=1,}

\newcommand{\mat}[1]{\begin{bmatrix}#1\end{bmatrix}}
\renewcommand{\d}{\mathrm{d}}

\begin{document}

\title{Physics 581, Assignment 1:\\Monte Carlo methods in computational physics}
\author{Casey Daniel and Chris Deimert}
\date{\today}

\maketitle

\section{Introduction}
\label{sec:introduction}

In this report, we explore a number of Monte Carlo numerical methods.
Monte Carlo methods use pseudorandom numbers to explore complicated systems.
These methods tend to converge slowly for simple problems, but can be very efficient for complex problems: especially those with a large number of variables.

\section{Random number generators}
\label{sec:random_number_generators}

\subsection{Pseudorandom numbers}
\label{subsec:pseudorandom_numbers}

First, we explore the generation of pseudo-random sequences of numbers.
These are key in any Monte Carlo method.

Most often, random number generators try to generate samples of a uniform random variable $ U $, whose probability distribution function is
\begin{align}
    f_U(u) &= \begin{cases} 1 & \text{if } 0 \leq u < 1 \\ 0 & \text{otherwise} \end{cases}
\end{align}
The mean of $ U $ is
\begin{align}
    \mu &= \int_{0}^{1} u \, \d u = \frac{1}{2}.
\end{align}
The variance is
\begin{align}
    \sigma^2 &= \int_0^1 \left(u - \mu\right)^2 \, \d u = \int_{-1/2}^{1/2} u'^2 \, \d u' = \frac{1}{12},
\end{align}
giving standard deviation of
\begin{align}
    \sigma &= \frac{1}{\sqrt{12}}.
\end{align}

We now explore some implementations of uniform random number generators, given in Press, Teukolsky, and Vetterling's ``Numerical Recipes.''
These are implemented in the random numbers module of Section~\ref{subsec:random_numbers_module_code}.
The first, \texttt{ran0}, implements a simple linear congruential method (LCM) generator:
\begin{align}
    I_{j+1} &= a I_j \mod m
\end{align}
where $ a = 7^5 $ and $ m = 2^{31}-1 $.
As a practical matter (avoiding overflow), this is implemented using
\begin{align}
I_{j+1} &= \begin{cases} a\left(I_j \mod q\right) - r[z/q] & \text{if it is} \geq 0 \\ a\left( I_j \mod q \right) - r[z/q] + m & \text{otherwise} \end{cases}
\end{align}
where $ a = 7^5 $, $ m = 2^{31} - 1 $, $ q = 127773 $, and $ r = 2836 $.
This generator is suggested as a baseline: any random number generator which does not perform at least as well as this one should probably not be used for serious work.
The \texttt{ran1} function uses the same LCM formula as \texttt{ran0}, but it also shuffles the resulting sequence around.
This helps to eliminate certain weaknesses which \texttt{ran0} is known to have.

The \texttt{ran2} generator combines two (LCM) generators with parameters $ m_1 = 2147483563 $, $ a_1 = 40014 $, $ q_1 = 53668 $, $ r_1 = 12211 $, $ m_2 = 2147483399 $, $ a_2 = 40692 $, $ q_2 = 52774 $, $ r_2 = 3791 $.
By combining two random generators together, we obtain a generator with a period of around $ 10^{18} $ which is a ``perfect'' random number generator for most practical purposes.

For all of the above LCM methods, the upper end point is never returned.
This is because of the use of $ (\mod m )$, which guarantees that all numbers $ I_j $ are at most $ m - 1 $.
Then the largest number returned is
\begin{align}
    \frac{m-1}{m} &< 1
\end{align}

The final generator, \texttt{ran3}, is from Donald Knuth, and it uses a subtractive method rather than an LCM method.
These methods use
\begin{align}
    I_j &= \left( I_{j-k} - I_{j-l} \right) \mod m
\end{align}
with fixed $ k $, $ l $, and $ m $.
Again, the upper end point can never be returned because of the $ (\mod m) $.

Each of these random number generators was tested with different numbers of iterations.
The gfortran intrinsic random generator is also included for comparison.
The errors in the mean and standard deviation of the resulting sequences compared to the theoretical mean and standard deviation are plotted in Figures~\ref{fig:random_generators_mean} and \ref{fig:random_generators_std_dev}.
It is seen that \texttt{ran0} deviates the furthest from the expected theoretical mean and standard deviation.
The others are roughly equivalent with the gfortran generator doing slightly better.

\begin{figure}[ht!]
    \begin{center}
    \includegraphics[width = 0.45\textwidth]{../Plots/Random_generators_mean.pdf}
    \caption{%
        Absolute difference between the means of pseudo-random sequences and the theoretical mean $ (1/2) $.
        Smaller values as sample size increases indicates a better random number generator.
    }
    \label{fig:random_generators_mean}
    \end{center}
\end{figure}

\begin{figure}[ht!]
    \begin{center}
    \includegraphics[width = 0.45\textwidth]{../Plots/Random_generators_std_dev.pdf}
    \caption{%
        Absolute difference between the standard deviations of pseudo-random sequences and the theoretical standard deviation $ (1/\sqrt{12}) $.
        Smaller values as sample size increases indicates a better random number generator.
    }
    \label{fig:random_generators_std_dev}
    \end{center}
\end{figure}

As another test, the autocorrelation function was calculated for the sequences of $ 10^6 $ numbers.
This is plotted in Figure~\ref{fig:random_generators_auto_corr}.
The \texttt{ran0} function again performs the worst: its autocorrelation is higher on average, and we can see peaks in the autocorrelation which indicate that certain elements of the sequence are strongly correlated to each other.
It is difficult to see the plots of the other three functions because of the sheer density of points.
It is important to plot with this density, though, because otherwise important features like the peaks in the \texttt{ran0} plot may be lost.
The other functions perform about the same in terms of autocorrelation: better than \texttt{ran0}, with lower autocorrelations on average and no major peaks.
All of the functions see an increase in the autocorrelation for higher values of $ k $.

\begin{figure}[ht!]
    \begin{center}
    \includegraphics[width = 0.45\textwidth]{../Plots/Random_generators_auto_corr.png}
    \caption{%
        Absolute value of the autocorrelation function for each random sequence.
        A truly random sequence should have an autocorrelation of close to zero for every $ k $.
    }
    \label{fig:random_generators_auto_corr}
    \end{center}
\end{figure}

\subsection{White noise from random numbers}
\label{subsec:white_noise_from_random_numbers}

The distribution for a uniform random variable $ X $ is given by
\begin{align}
    f_X(x) &= \begin{cases} \frac{1}{b-a} & \text{for } a \leq x \leq b \\ 0 & \text{otherwise} \end{cases}
\end{align}
It is easy to show that this distribution has expected value $ \left\langle X \right\rangle = \frac{1}{2} (a+b) $ and variance $ (\Delta X)^2 = \frac{1}{12} (b-a)^2 $.
We can obtain zero mean and unit variance by setting
\begin{align}
    a = -\sqrt{3} ; \qquad b = \sqrt{3}
\end{align}
In terms of the random variable $ U $ which is uniformly distributed on $ [0, 1) $, $ X $ is given by:
\begin{align}
    X &= 2 \sqrt{3} U - \sqrt{3}
\end{align}

An example of pseudo-randomly generated white-noise is plotted in Figure~\ref{fig:white_noise}, along with its autocorrelation.
As expected, the white noise is centred around zero, and most of the values are between $ -1 $ and $ 1 $.
Also, as expected, the autocorrelation is quite small: around 

\begin{figure}[ht!]
    \begin{center}
    \includegraphics[width = 0.45\textwidth]{../Plots/White_noise.pdf}
    \caption{%
        Sequence of 100 pseudorandom numbers simulating white noise, along with their autocorrelation.
        These were generated with the gfortran random number routine.
    }
    \label{fig:white_noise}
    \end{center}
\end{figure}

%\bigskip
%\begin{center}
%    \begin{tabular}{ccccc}
%        \toprule
%        Interval & Upper limit & LCM & gfortran & Exp. \\
%        \midrule
%        1  & 0.1 &  6 &  6 & 10 \\
%        2  & 0.2 & 11 & 16 & 10 \\
%        3  & 0.3 & 12 &  9 & 10 \\
%        4  & 0.4 &  9 &  6 & 10 \\
%        5  & 0.5 & 10 & 11 & 10 \\
%        6  & 0.6 &  9 &  5 & 10 \\
%        7  & 0.7 &  8 & 12 & 10 \\
%        8  & 0.8 & 10 &  9 & 10 \\
%        9  & 0.9 & 11 & 13 & 10 \\
%        10 & 1.0 & 14 & 13 & 10 \\
%        \bottomrule
%    \end{tabular}
%\end{center}
%\bigskip

\onecolumn

\section{Code}
\label{sec:code}

\subsection{Random generators code}
\label{subsec:random_generators_code}

\lstinputlisting[breaklines]{../Random_generators.f90}
\vspace{10pt}

\subsection{Random numbers module}
\label{subsec:random_numbers_module}

\lstinputlisting[breaklines]{../../Modules/Random_numbers_module.f90}
\vspace{10pt}

\subsection{Random generators plotting code}
\label{subsec:random_generators_plotting_code}

\lstinputlisting[breaklines]{../Random_generators.gp}
\vspace{10pt}

\end{document}
